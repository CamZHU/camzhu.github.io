---
layout: post
comments: false
title:  "White, Modayil, & Sutton (2014) AAAI"
excerpt: "curiosity, surprise, exploration"
date:   2016-09-06
mathjax: true
---

[*Surprise and Curiosity for Big Data Robotics*](http://homes.soic.indiana.edu/adamw/surprise.pdf)

Some new ideas in RL were presented in the paper such as `GVF`(general value function) and `MSPBE`(Mean Squared Projected Bellman Error).

In nutshell, GVF generalizes many core components of the original value function: 
\begin{equation}
v(s) = E_\pi[\sum \gamma^k R_{t+k+1} | S_t = s]
\end{equation}

The discount factor is now interpreted as the likelihood of termination, rewards as cumulants (which is accumulated future prediction errors).

In addition, MSPBE is a teaching signal that allows stochastic gradient descent to operate on. 

With these, the authors are able to introduce a rule-based curious behavior (a bit like improved e-greedy).
The control parameter Z is defined as:
\begin{equation}
Z_t^{(i)} = \frac{\delta^{(i)}}{\sqrt{var[\delta^{(i)}]}}
\end{equation}
where $\delta^{(i)}$ represents the prediction error for the ith GVF.

The decision rule states that if Z pass some pre-determined threshold, the behavioral policy will turn to be random otherwise follow the best policy (greedy).


Then they run an experiment to test this rule on the Create robot (showned below):
<img src="/images/paper7_1" style="width: 80%; height: 80%; margin-left: auto; margin-right: auto;">

There is a GVF that was learned from off-policy experience, which dedicates to predict future discounted battery current draw.


<img src="/images/paper7_2" style="width: 80%; height: 80%; margin-left: auto; margin-right: auto;">

Surprise was first observed in the early stage of learning (<15,000 timesteps). It is obvious since the robot was placed in a new environment, it should be surprised when it has lack of knowledge about environment.

On the 25,000 timestep, a 5 pound load was placed in the cargo bay of the robot. It will definitely influence the GVF's prediciton of future battery current. After the load, we can observe another peak of surprise and the behavioral policy distort toward random.




