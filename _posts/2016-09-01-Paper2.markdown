---
layout: post
comments: false
title:  "Gershman & Daw (2016) Ann Rev of Psy"
excerpt: "episodic memory, decision making, RL"
date:   2016-09-01
mathjax: true
---

Combining `episodic memory` & `decision making` is really becoming a thing!

Previous decision making models all (implicitly) assume some kinds of memory. 
For instances, we have seen semantic memory in model-based reinforcement learning, procedural memory in model-free reinforcement learning, and working memory in nearly every value-based decision models.

Episodic memory, which snapshot the context, is [now proved to be useful in decision making models](http://www.ncbi.nlm.nih.gov/pubmed/26999046).

The deep connections in computation level is also intriguing. 
Episodic memory is though to be best descried as non-parametric models (e.g., k-nearest neighbor, kernel machines, and Gaussian process etc).
Parametric models (e.g., deep neural network) could resemble the long-term memory where knowledge is cached in the learned weights of neural networks through repeated trainings.

Key ideas can also be found in [this paper](http://gershmanlab.webfactional.com/pubs/GershmanDaw17.pdf).

<img src="/images/paper2_1" style="width: 80%; height: 80%; margin-left: auto; margin-right: auto;">


How good is the bayesian non-parametric Reinforcement Learning ? (i.e., how would episodic memory improve behavioral policy of a RL agent) 


This is an interesting research question to answer.


